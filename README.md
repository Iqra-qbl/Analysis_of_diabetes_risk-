# Project XYZ

**Analysis of Diabetes Risk** is a comprehensive data analysis tool designed for medical professionals to streamline data exploration, analysis, and visualisation to analyze behavioural insights and impact of lifestyle factors on diabetes risk in India.

# ![CI logo](https://codeinstitute.s3.amazonaws.com/fullstack/ci_logo_small.png)


## Dataset Content
* The "Diabetes in Young Adults in India" dataset from Kaggle contains 100,000 record entries of synthetic but realistic data reflecting the prevalence of diabetes and associated factors among young adults (ages 15-25) in India. 

The dataset contains 100000 rows and 22 columns.

List of columns contains: ID, Age, Gender, Region, Family_Income, Family_History_Diabetes, Parent_Diabetes_Type, Genetic_Risk_Score, BMI, Physical_Activity_Level, Dietary_Habits, Fast_Food_Intake, Smoking, Alcohol_Consumption, Fasting_Blood_Sugar, HbA1c,Cholesterol_Level, Prediabetes, Diabetes_Type, Sleep_Hours, Stress_Level, Screen_Time.

There are no empty values.


## Hypothesis and how to validate?
* List here your project hypothesis(es) and how you envision validating it (them) 

## Project Plan
** Setup stage 0
* Set up the github repository and kanban board to track project files and progress respectively.
* Update readme file and jupyter notebook in Code Institute repository template.
* Upload the dataset "Diabetes in Young Adults in India" from kaggle into workspace.
* Start coding

** ETL Stage 1 (Data extraction, transformation and loading )
* Imported packages from commonly used python libraries 
* Checking and analyzing initial dataset information regarding column names, total number of rows and columns,  datatypes, empty values.
* Transforming dataypes into numeric datatype


## The rationale to map the business requirements to the Data Visualisations
* List your business requirements and a rationale to map them to the Data Visualisations

## Analysis techniques used
* List the data analysis methods used and explain limitations or alternative approaches.
* How did you structure the data analysis techniques. Justify your response.
* Did the data limit you, and did you use an alternative approach to meet these challenges?
* How did you use generative AI tools to help with ideation, design thinking and code optimisation?

## Ethical considerations
* Were there any data privacy, bias or fairness issues with the data?
* How did you overcome any legal or societal issues?



## Unfixed Bugs
* Please mention unfixed bugs and why they were not fixed. This section should include shortcomings of the frameworks or technologies used. Although time can be a significant variable to consider, paucity of time and difficulty understanding implementation are not valid reasons to leave bugs unfixed.
* Did you recognise gaps in your knowledge, and how did you address them?
* If applicable, include evidence of feedback received (from peers or instructors) and how it improved your approach or understanding.

## Development Roadmap
* What challenges did you face, and what strategies were used to overcome these challenges?
* What new skills or tools do you plan to learn next based on your project experience? 

## Deployment
### Heroku

* The App live link is: https://YOUR_APP_NAME.herokuapp.com/ 
* Set the runtime.txt Python version to a [Heroku-20](https://devcenter.heroku.com/articles/python-support#supported-runtimes) stack currently supported version.
* The project was deployed to Heroku using the following steps.

1. Log in to Heroku and create an App
2. From the Deploy tab, select GitHub as the deployment method.
3. Select your repository name and click Search. Once it is found, click Connect.
4. Select the branch you want to deploy, then click Deploy Branch.
5. The deployment process should happen smoothly if all deployment files are fully functional. Click now the button Open App on the top of the page to access your App.
6. If the slug size is too large then add large files not required for the app to the .slugignore file.


## Main Data Analysis Libraries
* Here you should list the libraries you used in the project and provide an example(s) of how you used these libraries.


## Credits 

* Dateset 

### Content 

- Readme and Jupyter notebook() template was built using Code Institute sample Readme file.
- Importing packages snippet was taken from Code institute LMS: Data Visualisation section.
- Checking and analyzing initial dataset code snippets were taken from website: https://www.dataquest.io/cheat-sheet/pandas-cheat-sheet/ 
- Instructions on how to implement form validation on the Sign-Up page was taken from [Specific YouTube Tutorial](https://www.youtube.com/)
- The icons in the footer were taken from [Font Awesome](https://fontawesome.com/)

### Media

- The photos used on the home and sign-up page are from This Open-Source site
- The images used for the gallery page were taken from this other open-source site



## Acknowledgements (optional)
* Thank the people who provided support through this project.